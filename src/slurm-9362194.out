***************************************************************************************************** 
* WARNING: The 2022 software stack is deprecated. Please consider switching to
the latest 2024 * 
* software stack, or the older 2023 software stack. * 
* * 
* If you have any question, please contact us via
http://servicedesk.surfsara.nl. * 
***************************************************************************************************** 

----------------------------------------------------------------------------
  Anaconda3: Anaconda3/2022.05
----------------------------------------------------------------------------
    Description:
      Built to complement the rich, open source Python community, the
      Anaconda platform provides an enterprise-ready data analytics
      platform that empowers companies to adopt a modern open data science
      analytics architecture. 


    You will need to load all module(s) on any one of the lines below before the "Anaconda3/2022.05" module is available to load.

      2022
 
    Help:
      
      Description
      ===========
      Built to complement the rich, open source Python community,
      the Anaconda platform provides an enterprise-ready data analytics platform 
      that empowers companies to adopt a modern open data science analytics architecture.
      
      
      More information
      ================
       - Homepage: https://www.anaconda.com
      


 

Running benchmark `h2oautoml` on `openml/t/146204` framework in `singularity` mode.
Loading frameworks definitions from ['/gpfs/home4/smukherjee/automlbenchmark/resources/frameworks.yaml'].
Loading benchmark constraint definitions from ['/gpfs/home4/smukherjee/automlbenchmark/resources/constraints.yaml'].
Loading openml task 146204.
Looking for the image /gpfs/home4/smukherjee/automlbenchmark/frameworks/H2OAutoML/.setup/h2oautoml_stable-dev.sif

----------------------------------------------------------------------------
Starting job singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML.
[MONITORING] [singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML] CPU Utilization: 1.3%
Starting Singularity: singularity run --pwd /bench  -B /gpfs/home4/smukherjee:/input -B /gpfs/home4/smukherjee/automl_data/results/h2oautoml.openml_t_146204.test.singularity.20250110T182427:/output -B /gpfs/home4/smukherjee/.config/automlbenchmark:/custom /gpfs/home4/smukherjee/automlbenchmark/frameworks/H2OAutoML/.setup/h2oautoml_stable-dev.sif "h2oautoml openml/t/146204 test   -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session=".
[MONITORING] [singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML] Memory Usage: 5.7%
Datasets are loaded by default from folder /gpfs/home4/smukherjee.
[MONITORING] [singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML] Disk Usage: 1.9%
Generated files will be available in folder /gpfs/home4/smukherjee/automl_data/results.
Running cmd `singularity run --pwd /bench  -B /gpfs/home4/smukherjee:/input -B /gpfs/home4/smukherjee/automl_data/results/h2oautoml.openml_t_146204.test.singularity.20250110T182427:/output -B /gpfs/home4/smukherjee/.config/automlbenchmark:/custom /gpfs/home4/smukherjee/automlbenchmark/frameworks/H2OAutoML/.setup/h2oautoml_stable-dev.sif "h2oautoml openml/t/146204 test   -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session="`
declare: invalid option "-m"
declare: invalid option "-m"
Running benchmark `h2oautoml` on `openml/t/146204` framework in `local` mode.
Loading frameworks definitions from ['/bench/resources/frameworks.yaml'].
Loading benchmark constraint definitions from ['/bench/resources/constraints.yaml'].
Loading openml task 146204.
Running 5 jobs
[MONITORING] [python3.9 [1983536]] CPU Utilization: 3.2%

----------------------------------------------------------
Starting job local.openml_t_146204.test.led24.0.H2OAutoML.
Assigning 16 cores (total=192) for new task led24.
[MONITORING] [python3.9 [1983536]] Memory Usage: 6.1%
[MONITORING] [python3.9 [1983536]] Disk Usage: 0.0%
Assigning 361017 MB (total=386603 MB) for new led24 task.
Running task led24 on framework H2OAutoML with config:
TaskConfig({'framework': 'H2OAutoML', 'framework_params': {'_save_artifacts': ['leaderboard', 'model_predictions']}, 'framework_version': '3.46.0.6', 'type': 'classification', 'name': 'led24', 'openml_task_id': 146204, 'test_server': False, 'fold': 0, 'metric': 'logloss', 'metrics': ['logloss', 'acc', 'balacc'], 'seed': 769006596, 'job_timeout_seconds': 600, 'max_runtime_seconds': 300, 'cores': 16, 'max_mem_size_mb': 361017, 'min_vol_size_mb': -1, 'input_dir': '/input', 'output_dir': '/output/', 'output_predictions_file': '/output/predictions/led24/0/predictions.csv', 'tag': None, 'command': 'runbenchmark.py h2oautoml openml/t/146204 test -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session=', 'git_info': {'repo': 'https://github.com/SubhadityaMukherjee/automlbenchmark.git', 'branch': 'singularity', 'commit': '7980953509ddbe0c961203f526b6110f33d9cc4e', 'tags': [], 'status': ['## singularity...origin/singularity', ' M amlb/runners/singularity.py', ' M frameworks/autosklearn/exec.py', ' M resources/constraints.yaml']}, 'measure_inference_time': False, 'ext': {}, 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'type_': 'multiclass', 'output_metadata_file': '/output/predictions/led24/0/metadata.json'})
expected str, bytes or os.PathLike object, not NoneType
Traceback (most recent call last):
  File "/bench/amlb/benchmark.py", line 791, in run
    meta_result = self.benchmark.framework_module.run(
  File "/bench/frameworks/H2OAutoML/__init__.py", line 15, in run
    train=dict(path=dataset.train.path),
  File "/bench/amlb/data.py", line 120, in path
    return self.data_path(self.format)
  File "/bench/amlb/datasets/openml.py", line 348, in data_path
    return self._get_data(format)
  File "/bench/amlb/datasets/openml.py", line 364, in _get_data
    self.dataset._load_data(fmt)
  File "/bench/amlb/datasets/openml.py", line 318, in _load_data
    train, test = splitter.split()
  File "/bench/amlb/utils/process.py", line 967, in profiler
    return fn(*args, **kwargs)
  File "/bench/amlb/datasets/openml.py", line 419, in split
    train_path, test_path = self.ds._get_split_paths(".arff")
  File "/bench/amlb/datasets/openml.py", line 329, in _get_split_paths
    sp = split_path(self._oml_dataset.data_file)
  File "/bench/amlb/utils/os.py", line 31, in split_path
    dir, file = os.path.split(path)
  File "/usr/lib/python3.9/posixpath.py", line 103, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
Loading metadata from `/output/predictions/led24/0/metadata.json`.
Metric scores: { 'acc': nan,
  'app_version': 'dev '
                 '[https://github.com/SubhadityaMukherjee/automlbenchmark.git, '
                 'singularity, 7980953]',
  'balacc': nan,
  'constraint': 'test',
  'duration': nan,
  'fold': 0,
  'framework': 'H2OAutoML',
  'id': 'openml.org/t/146204',
  'info': 'TypeError: expected str, bytes or os.PathLike object, not NoneType',
  'logloss': nan,
  'metric': 'neg_logloss',
  'mode': 'singularity',
  'models_count': nan,
  'params': "{'_save_artifacts': ['leaderboard', 'model_predictions']}",
  'predict_duration': nan,
  'result': nan,
  'seed': 769006596,
  'task': 'led24',
  'training_duration': nan,
  'type': 'multiclass',
  'utc': '2025-01-10T18:24:30',
  'version': '3.46.0.6'}
Job `local.openml_t_146204.test.led24.0.H2OAutoML` executed in 0.009 seconds.
Scores saved to `/output/scores/results.csv`.
Scores saved to `/output/results.csv`.

----------------------------------------------------------
Starting job local.openml_t_146204.test.led24.1.H2OAutoML.
Assigning 16 cores (total=192) for new task led24.
Assigning 360974 MB (total=386603 MB) for new led24 task.
Running task led24 on framework H2OAutoML with config:
TaskConfig({'framework': 'H2OAutoML', 'framework_params': {'_save_artifacts': ['leaderboard', 'model_predictions']}, 'framework_version': '3.46.0.6', 'type': 'classification', 'name': 'led24', 'openml_task_id': 146204, 'test_server': False, 'fold': 1, 'metric': 'logloss', 'metrics': ['logloss', 'acc', 'balacc'], 'seed': 769006597, 'job_timeout_seconds': 600, 'max_runtime_seconds': 300, 'cores': 16, 'max_mem_size_mb': 360974, 'min_vol_size_mb': -1, 'input_dir': '/input', 'output_dir': '/output/', 'output_predictions_file': '/output/predictions/led24/1/predictions.csv', 'tag': None, 'command': 'runbenchmark.py h2oautoml openml/t/146204 test -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session=', 'git_info': {'repo': 'https://github.com/SubhadityaMukherjee/automlbenchmark.git', 'branch': 'singularity', 'commit': '7980953509ddbe0c961203f526b6110f33d9cc4e', 'tags': [], 'status': ['## singularity...origin/singularity', ' M amlb/runners/singularity.py', ' M frameworks/autosklearn/exec.py', ' M resources/constraints.yaml']}, 'measure_inference_time': False, 'ext': {}, 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'type_': 'multiclass', 'output_metadata_file': '/output/predictions/led24/1/metadata.json'})
expected str, bytes or os.PathLike object, not NoneType
Traceback (most recent call last):
  File "/bench/amlb/benchmark.py", line 791, in run
    meta_result = self.benchmark.framework_module.run(
  File "/bench/frameworks/H2OAutoML/__init__.py", line 15, in run
    train=dict(path=dataset.train.path),
  File "/bench/amlb/data.py", line 120, in path
    return self.data_path(self.format)
  File "/bench/amlb/datasets/openml.py", line 348, in data_path
    return self._get_data(format)
  File "/bench/amlb/datasets/openml.py", line 364, in _get_data
    self.dataset._load_data(fmt)
  File "/bench/amlb/datasets/openml.py", line 318, in _load_data
    train, test = splitter.split()
  File "/bench/amlb/utils/process.py", line 967, in profiler
    return fn(*args, **kwargs)
  File "/bench/amlb/datasets/openml.py", line 419, in split
    train_path, test_path = self.ds._get_split_paths(".arff")
  File "/bench/amlb/datasets/openml.py", line 329, in _get_split_paths
    sp = split_path(self._oml_dataset.data_file)
  File "/bench/amlb/utils/os.py", line 31, in split_path
    dir, file = os.path.split(path)
  File "/usr/lib/python3.9/posixpath.py", line 103, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
Loading metadata from `/output/predictions/led24/1/metadata.json`.
Metric scores: { 'acc': nan,
  'app_version': 'dev '
                 '[https://github.com/SubhadityaMukherjee/automlbenchmark.git, '
                 'singularity, 7980953]',
  'balacc': nan,
  'constraint': 'test',
  'duration': nan,
  'fold': 1,
  'framework': 'H2OAutoML',
  'id': 'openml.org/t/146204',
  'info': 'TypeError: expected str, bytes or os.PathLike object, not NoneType',
  'logloss': nan,
  'metric': 'neg_logloss',
  'mode': 'singularity',
  'models_count': nan,
  'params': "{'_save_artifacts': ['leaderboard', 'model_predictions']}",
  'predict_duration': nan,
  'result': nan,
  'seed': 769006597,
  'task': 'led24',
  'training_duration': nan,
  'type': 'multiclass',
  'utc': '2025-01-10T18:24:32',
  'version': '3.46.0.6'}
Job `local.openml_t_146204.test.led24.1.H2OAutoML` executed in 1.247 seconds.
Scores saved to `/output/scores/results.csv`.
Scores saved to `/output/results.csv`.

----------------------------------------------------------
Starting job local.openml_t_146204.test.led24.2.H2OAutoML.
Assigning 16 cores (total=192) for new task led24.
Assigning 360761 MB (total=386603 MB) for new led24 task.
Running task led24 on framework H2OAutoML with config:
TaskConfig({'framework': 'H2OAutoML', 'framework_params': {'_save_artifacts': ['leaderboard', 'model_predictions']}, 'framework_version': '3.46.0.6', 'type': 'classification', 'name': 'led24', 'openml_task_id': 146204, 'test_server': False, 'fold': 2, 'metric': 'logloss', 'metrics': ['logloss', 'acc', 'balacc'], 'seed': 769006598, 'job_timeout_seconds': 600, 'max_runtime_seconds': 300, 'cores': 16, 'max_mem_size_mb': 360761, 'min_vol_size_mb': -1, 'input_dir': '/input', 'output_dir': '/output/', 'output_predictions_file': '/output/predictions/led24/2/predictions.csv', 'tag': None, 'command': 'runbenchmark.py h2oautoml openml/t/146204 test -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session=', 'git_info': {'repo': 'https://github.com/SubhadityaMukherjee/automlbenchmark.git', 'branch': 'singularity', 'commit': '7980953509ddbe0c961203f526b6110f33d9cc4e', 'tags': [], 'status': ['## singularity...origin/singularity', ' M amlb/runners/singularity.py', ' M frameworks/autosklearn/exec.py', ' M resources/constraints.yaml']}, 'measure_inference_time': False, 'ext': {}, 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'type_': 'multiclass', 'output_metadata_file': '/output/predictions/led24/2/metadata.json'})
expected str, bytes or os.PathLike object, not NoneType
Traceback (most recent call last):
  File "/bench/amlb/benchmark.py", line 791, in run
    meta_result = self.benchmark.framework_module.run(
  File "/bench/frameworks/H2OAutoML/__init__.py", line 15, in run
    train=dict(path=dataset.train.path),
  File "/bench/amlb/data.py", line 120, in path
    return self.data_path(self.format)
  File "/bench/amlb/datasets/openml.py", line 348, in data_path
    return self._get_data(format)
  File "/bench/amlb/datasets/openml.py", line 364, in _get_data
    self.dataset._load_data(fmt)
  File "/bench/amlb/datasets/openml.py", line 318, in _load_data
    train, test = splitter.split()
  File "/bench/amlb/utils/process.py", line 967, in profiler
    return fn(*args, **kwargs)
  File "/bench/amlb/datasets/openml.py", line 419, in split
    train_path, test_path = self.ds._get_split_paths(".arff")
  File "/bench/amlb/datasets/openml.py", line 329, in _get_split_paths
    sp = split_path(self._oml_dataset.data_file)
  File "/bench/amlb/utils/os.py", line 31, in split_path
    dir, file = os.path.split(path)
  File "/usr/lib/python3.9/posixpath.py", line 103, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
Loading metadata from `/output/predictions/led24/2/metadata.json`.
Metric scores: { 'acc': nan,
  'app_version': 'dev '
                 '[https://github.com/SubhadityaMukherjee/automlbenchmark.git, '
                 'singularity, 7980953]',
  'balacc': nan,
  'constraint': 'test',
  'duration': nan,
  'fold': 2,
  'framework': 'H2OAutoML',
  'id': 'openml.org/t/146204',
  'info': 'TypeError: expected str, bytes or os.PathLike object, not NoneType',
  'logloss': nan,
  'metric': 'neg_logloss',
  'mode': 'singularity',
  'models_count': nan,
  'params': "{'_save_artifacts': ['leaderboard', 'model_predictions']}",
  'predict_duration': nan,
  'result': nan,
  'seed': 769006598,
  'task': 'led24',
  'training_duration': nan,
  'type': 'multiclass',
  'utc': '2025-01-10T18:24:32',
  'version': '3.46.0.6'}
Job `local.openml_t_146204.test.led24.2.H2OAutoML` executed in 0.003 seconds.
Scores saved to `/output/scores/results.csv`.
Scores saved to `/output/results.csv`.

----------------------------------------------------------
Starting job local.openml_t_146204.test.led24.3.H2OAutoML.
Assigning 16 cores (total=192) for new task led24.
Assigning 360758 MB (total=386603 MB) for new led24 task.
Running task led24 on framework H2OAutoML with config:
TaskConfig({'framework': 'H2OAutoML', 'framework_params': {'_save_artifacts': ['leaderboard', 'model_predictions']}, 'framework_version': '3.46.0.6', 'type': 'classification', 'name': 'led24', 'openml_task_id': 146204, 'test_server': False, 'fold': 3, 'metric': 'logloss', 'metrics': ['logloss', 'acc', 'balacc'], 'seed': 769006599, 'job_timeout_seconds': 600, 'max_runtime_seconds': 300, 'cores': 16, 'max_mem_size_mb': 360758, 'min_vol_size_mb': -1, 'input_dir': '/input', 'output_dir': '/output/', 'output_predictions_file': '/output/predictions/led24/3/predictions.csv', 'tag': None, 'command': 'runbenchmark.py h2oautoml openml/t/146204 test -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session=', 'git_info': {'repo': 'https://github.com/SubhadityaMukherjee/automlbenchmark.git', 'branch': 'singularity', 'commit': '7980953509ddbe0c961203f526b6110f33d9cc4e', 'tags': [], 'status': ['## singularity...origin/singularity', ' M amlb/runners/singularity.py', ' M frameworks/autosklearn/exec.py', ' M resources/constraints.yaml']}, 'measure_inference_time': False, 'ext': {}, 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'type_': 'multiclass', 'output_metadata_file': '/output/predictions/led24/3/metadata.json'})
expected str, bytes or os.PathLike object, not NoneType
Traceback (most recent call last):
  File "/bench/amlb/benchmark.py", line 791, in run
    meta_result = self.benchmark.framework_module.run(
  File "/bench/frameworks/H2OAutoML/__init__.py", line 15, in run
    train=dict(path=dataset.train.path),
  File "/bench/amlb/data.py", line 120, in path
    return self.data_path(self.format)
  File "/bench/amlb/datasets/openml.py", line 348, in data_path
    return self._get_data(format)
  File "/bench/amlb/datasets/openml.py", line 364, in _get_data
    self.dataset._load_data(fmt)
  File "/bench/amlb/datasets/openml.py", line 318, in _load_data
    train, test = splitter.split()
  File "/bench/amlb/utils/process.py", line 967, in profiler
    return fn(*args, **kwargs)
  File "/bench/amlb/datasets/openml.py", line 419, in split
    train_path, test_path = self.ds._get_split_paths(".arff")
  File "/bench/amlb/datasets/openml.py", line 329, in _get_split_paths
    sp = split_path(self._oml_dataset.data_file)
  File "/bench/amlb/utils/os.py", line 31, in split_path
    dir, file = os.path.split(path)
  File "/usr/lib/python3.9/posixpath.py", line 103, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
Loading metadata from `/output/predictions/led24/3/metadata.json`.
Metric scores: { 'acc': nan,
  'app_version': 'dev '
                 '[https://github.com/SubhadityaMukherjee/automlbenchmark.git, '
                 'singularity, 7980953]',
  'balacc': nan,
  'constraint': 'test',
  'duration': nan,
  'fold': 3,
  'framework': 'H2OAutoML',
  'id': 'openml.org/t/146204',
  'info': 'TypeError: expected str, bytes or os.PathLike object, not NoneType',
  'logloss': nan,
  'metric': 'neg_logloss',
  'mode': 'singularity',
  'models_count': nan,
  'params': "{'_save_artifacts': ['leaderboard', 'model_predictions']}",
  'predict_duration': nan,
  'result': nan,
  'seed': 769006599,
  'task': 'led24',
  'training_duration': nan,
  'type': 'multiclass',
  'utc': '2025-01-10T18:24:32',
  'version': '3.46.0.6'}
Job `local.openml_t_146204.test.led24.3.H2OAutoML` executed in 0.002 seconds.
Scores saved to `/output/scores/results.csv`.
Scores saved to `/output/results.csv`.

----------------------------------------------------------
Starting job local.openml_t_146204.test.led24.4.H2OAutoML.
Assigning 16 cores (total=192) for new task led24.
Assigning 360753 MB (total=386603 MB) for new led24 task.
Running task led24 on framework H2OAutoML with config:
TaskConfig({'framework': 'H2OAutoML', 'framework_params': {'_save_artifacts': ['leaderboard', 'model_predictions']}, 'framework_version': '3.46.0.6', 'type': 'classification', 'name': 'led24', 'openml_task_id': 146204, 'test_server': False, 'fold': 4, 'metric': 'logloss', 'metrics': ['logloss', 'acc', 'balacc'], 'seed': 769006600, 'job_timeout_seconds': 600, 'max_runtime_seconds': 300, 'cores': 16, 'max_mem_size_mb': 360753, 'min_vol_size_mb': -1, 'input_dir': '/input', 'output_dir': '/output/', 'output_predictions_file': '/output/predictions/led24/4/predictions.csv', 'tag': None, 'command': 'runbenchmark.py h2oautoml openml/t/146204 test -Xseed=auto -i /input -o /output -u /custom -s skip -Xrun_mode=singularity --session=', 'git_info': {'repo': 'https://github.com/SubhadityaMukherjee/automlbenchmark.git', 'branch': 'singularity', 'commit': '7980953509ddbe0c961203f526b6110f33d9cc4e', 'tags': [], 'status': ['## singularity...origin/singularity', ' M amlb/runners/singularity.py', ' M frameworks/autosklearn/exec.py', ' M resources/constraints.yaml']}, 'measure_inference_time': False, 'ext': {}, 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'type_': 'multiclass', 'output_metadata_file': '/output/predictions/led24/4/metadata.json'})
expected str, bytes or os.PathLike object, not NoneType
Traceback (most recent call last):
  File "/bench/amlb/benchmark.py", line 791, in run
    meta_result = self.benchmark.framework_module.run(
  File "/bench/frameworks/H2OAutoML/__init__.py", line 15, in run
    train=dict(path=dataset.train.path),
  File "/bench/amlb/data.py", line 120, in path
    return self.data_path(self.format)
  File "/bench/amlb/datasets/openml.py", line 348, in data_path
    return self._get_data(format)
  File "/bench/amlb/datasets/openml.py", line 364, in _get_data
    self.dataset._load_data(fmt)
  File "/bench/amlb/datasets/openml.py", line 318, in _load_data
    train, test = splitter.split()
  File "/bench/amlb/utils/process.py", line 967, in profiler
    return fn(*args, **kwargs)
  File "/bench/amlb/datasets/openml.py", line 419, in split
    train_path, test_path = self.ds._get_split_paths(".arff")
  File "/bench/amlb/datasets/openml.py", line 329, in _get_split_paths
    sp = split_path(self._oml_dataset.data_file)
  File "/bench/amlb/utils/os.py", line 31, in split_path
    dir, file = os.path.split(path)
  File "/usr/lib/python3.9/posixpath.py", line 103, in split
    p = os.fspath(p)
TypeError: expected str, bytes or os.PathLike object, not NoneType
Loading metadata from `/output/predictions/led24/4/metadata.json`.
Metric scores: { 'acc': nan,
  'app_version': 'dev '
                 '[https://github.com/SubhadityaMukherjee/automlbenchmark.git, '
                 'singularity, 7980953]',
  'balacc': nan,
  'constraint': 'test',
  'duration': nan,
  'fold': 4,
  'framework': 'H2OAutoML',
  'id': 'openml.org/t/146204',
  'info': 'TypeError: expected str, bytes or os.PathLike object, not NoneType',
  'logloss': nan,
  'metric': 'neg_logloss',
  'mode': 'singularity',
  'models_count': nan,
  'params': "{'_save_artifacts': ['leaderboard', 'model_predictions']}",
  'predict_duration': nan,
  'result': nan,
  'seed': 769006600,
  'task': 'led24',
  'training_duration': nan,
  'type': 'multiclass',
  'utc': '2025-01-10T18:24:32',
  'version': '3.46.0.6'}
Job `local.openml_t_146204.test.led24.4.H2OAutoML` executed in 0.002 seconds.
Scores saved to `/output/scores/results.csv`.
Scores saved to `/output/results.csv`.
All jobs executed in 2.088 seconds.
[MONITORING] [python3.9 [1983536]] CPU Utilization: 2.0%
[MONITORING] [python3.9 [1983536]] Memory Usage: 6.2%
[MONITORING] [python3.9 [1983536]] Disk Usage: 0.0%
Processing results for 
Summing up scores for current run:
                 id  task  fold framework constraint      metric  duration      seed                                                               info
openml.org/t/146204 led24     0 H2OAutoML       test neg_logloss     0.009 769006596 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     1 H2OAutoML       test neg_logloss     1.200 769006597 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     2 H2OAutoML       test neg_logloss     0.003 769006598 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     3 H2OAutoML       test neg_logloss     0.002 769006599 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     4 H2OAutoML       test neg_logloss     0.002 769006600 TypeError: expected str, bytes or os.PathLike object, not NoneType
Job `singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML` executed in 4.850 seconds.
All jobs executed in 4.851 seconds.
[MONITORING] [singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML] CPU Utilization: 4.7%
[MONITORING] [singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML] Memory Usage: 6.1%
[MONITORING] [singularity.openml_t_146204.test.all_tasks.all_folds.H2OAutoML] Disk Usage: 1.9%
Summing up scores for current run:
                 id  task  fold framework constraint      metric  duration      seed                                                               info
openml.org/t/146204 led24     0 H2OAutoML       test neg_logloss     0.009 769006596 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     1 H2OAutoML       test neg_logloss     1.200 769006597 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     2 H2OAutoML       test neg_logloss     0.003 769006598 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     3 H2OAutoML       test neg_logloss     0.002 769006599 TypeError: expected str, bytes or os.PathLike object, not NoneType
openml.org/t/146204 led24     4 H2OAutoML       test neg_logloss     0.002 769006600 TypeError: expected str, bytes or os.PathLike object, not NoneType
python: can't open file '/home/smukherjee/scripts/report_generator.py': [Errno 2] No such file or directory
/var/spool/slurm/slurmd/job9362194/slurm_script: line 21: deactivate: No such file or directory

JOB STATISTICS
==============
Job ID: 9362194
Cluster: snellius
User/Group: smukherjee/smukherjee
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 16
CPU Utilized: 00:00:13
CPU Efficiency: 3.01% of 00:07:12 core-walltime
Job Wall-clock time: 00:00:27
Memory Utilized: 2.19 MB
Memory Efficiency: 0.00% of 56.00 GB
